{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f37af03",
   "metadata": {},
   "source": [
    "Word vectors occupy lot of space. hence en_core_web_sm model do not have them included. In order to download word vectors you need to install large or medium english model. We will install the large one! make sure you have run \"python -m spacy download en_core_web_lg\" to install large english model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15d8d94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "579ea79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog Vector: True OOV: False\n",
      "cat Vector: True OOV: False\n",
      "banana Vector: True OOV: False\n",
      "kem Vector: True OOV: False\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"dog cat banana kem\")\n",
    "for token in doc:\n",
    "    print(token.text, \"Vector:\", token.has_vector, \"OOV:\",token.is_oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f490a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0].vector.shape     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "890ac393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.0176e-01,  3.7057e-01,  2.1281e-02, -3.4125e-01,  4.9538e-02,\n",
       "        2.9440e-01, -1.7376e-01, -2.7982e-01,  6.7622e-02,  2.1693e+00,\n",
       "       -6.2691e-01,  2.9106e-01, -6.7270e-01,  2.3319e-01, -3.4264e-01,\n",
       "        1.8311e-01,  5.0226e-01,  1.0689e+00,  1.4698e-01, -4.5230e-01,\n",
       "       -4.1827e-01, -1.5967e-01,  2.6748e-01, -4.8867e-01,  3.6462e-01,\n",
       "       -4.3403e-02, -2.4474e-01, -4.1752e-01,  8.9088e-02, -2.5552e-01,\n",
       "       -5.5695e-01,  1.2243e-01, -8.3526e-02,  5.5095e-01,  3.6410e-01,\n",
       "        1.5361e-01,  5.5738e-01, -9.0702e-01, -4.9098e-02,  3.8580e-01,\n",
       "        3.8000e-01,  1.4425e-01, -2.7221e-01, -3.7016e-01, -1.2904e-01,\n",
       "       -1.5085e-01, -3.8076e-01,  4.9583e-02,  1.2755e-01, -8.2788e-02,\n",
       "        1.4339e-01,  3.2537e-01,  2.7226e-01,  4.3632e-01, -3.1769e-01,\n",
       "        7.9405e-01,  2.6529e-01,  1.0135e-01, -3.3279e-01,  4.3117e-01,\n",
       "        1.6687e-01,  1.0729e-01,  8.9418e-02,  2.8635e-01,  4.0117e-01,\n",
       "       -3.9222e-01,  4.5217e-01,  1.3521e-01, -2.8878e-01, -2.2819e-02,\n",
       "       -3.4975e-01, -2.2996e-01,  2.0224e-01, -2.1177e-01,  2.7184e-01,\n",
       "        9.1703e-02, -2.0610e-01, -6.5758e-01,  1.8949e-01, -2.6756e-01,\n",
       "        9.2639e-02,  4.3316e-01, -4.8868e-01, -3.8309e-01, -2.1910e-01,\n",
       "       -4.4183e-01,  9.8044e-01,  6.7423e-01,  8.4003e-01, -1.8169e-01,\n",
       "        1.7385e-01,  4.1848e-01,  1.6098e-01, -1.0490e-01, -4.1965e-01,\n",
       "       -3.5660e-01, -1.6837e-01, -6.3458e-01,  3.8422e-01, -3.5043e-01,\n",
       "        1.7486e-01,  5.3528e-01,  2.0143e-01,  3.7877e-02,  4.7105e-01,\n",
       "       -4.4344e-01,  1.6840e-01, -1.6685e-01, -2.4022e-01, -1.0077e-01,\n",
       "        3.0334e-01,  4.2730e-01,  3.3803e-01, -4.3481e-01,  1.1343e-01,\n",
       "        6.1958e-02,  6.1808e-02, -1.4007e-01,  8.2018e-02, -3.9130e-02,\n",
       "        5.1442e-02,  2.8725e-01,  5.8025e-01, -5.7641e-01, -3.4652e-01,\n",
       "        1.0132e-01,  1.4463e-01,  1.1569e-02, -3.3701e-01, -1.7586e-01,\n",
       "       -3.5724e-01, -2.1423e-01,  1.1429e-02,  4.7645e-01, -3.7463e-02,\n",
       "       -2.9488e-01, -1.7465e-01,  3.0255e-01,  6.0317e-01, -6.6790e-02,\n",
       "       -2.7050e+00, -7.0308e-01,  4.0548e-01,  6.2874e-01,  6.3080e-01,\n",
       "       -5.4513e-01, -9.6191e-03,  2.6533e-01,  2.3391e-01, -5.1886e-02,\n",
       "       -6.5759e-03,  1.8573e-02, -4.5693e-01, -7.0351e-02, -3.0621e-01,\n",
       "       -1.4018e-02, -2.0408e-01,  3.7100e-01, -3.2354e-01, -8.4646e-01,\n",
       "        2.7092e-01, -1.1961e-01, -9.5576e-02, -6.0464e-01,  4.2409e-02,\n",
       "        2.4656e-01,  3.8445e-02, -2.5467e-02, -9.2908e-02, -2.1356e-01,\n",
       "        3.6120e-01,  1.9113e-02,  6.2741e-02, -1.3083e-01, -1.5146e-03,\n",
       "        5.8238e-01, -1.8956e-01,  7.8105e-01,  1.0477e-02,  1.0928e+00,\n",
       "        1.0140e-01, -3.6248e-01, -1.1962e-01, -3.4462e-01, -5.5704e-01,\n",
       "        2.5797e-01,  3.3356e-01,  3.3194e-01, -3.1298e-01, -7.5547e-01,\n",
       "       -7.5290e-01, -9.3072e-02, -1.1173e-01, -5.7251e-01,  1.6639e-01,\n",
       "        6.3579e-01,  2.4006e-01, -2.9211e-01,  9.0182e-01,  1.2425e-01,\n",
       "       -5.7751e-01,  4.7986e-02, -4.2748e-01,  2.4446e-01,  4.7232e-02,\n",
       "        3.5694e-01,  4.4241e-01, -2.3055e-01,  6.6037e-01, -7.3983e-03,\n",
       "       -3.7857e-01,  2.2759e-01, -3.7138e-01,  3.1055e-01, -7.2105e-02,\n",
       "       -2.4490e-01, -3.9761e-02,  5.3650e-01, -4.1478e-01,  1.6563e-01,\n",
       "        3.3707e-01,  1.0920e-01,  3.7219e-01, -5.5727e-01, -7.8060e-01,\n",
       "        1.4251e-01, -3.5828e-01,  4.1638e-01,  2.1446e-01,  1.8410e-01,\n",
       "       -4.7704e-01, -2.2005e-02, -2.3634e-01, -2.2840e-01,  3.4722e-01,\n",
       "        2.3667e-01,  7.4249e-02, -8.8416e-02,  2.8618e-01, -4.6942e-01,\n",
       "       -4.3914e-01, -2.6474e-01, -3.0690e-01, -1.5260e-01, -8.4870e-02,\n",
       "        2.8410e-01, -1.8481e-01, -2.2122e-01, -1.1169e-01, -2.5241e-02,\n",
       "        4.5968e-02,  3.5343e-02,  2.2467e-01,  5.1556e-01, -6.5137e-04,\n",
       "        9.9559e-02, -1.4215e-01,  2.0136e-01,  2.8334e-01, -2.8772e-01,\n",
       "        3.7766e-02, -3.7608e-01, -1.1681e-01, -6.7020e-01, -4.6265e-02,\n",
       "        3.8784e-01, -3.2295e-02, -5.4291e-02, -4.5384e-01,  1.9552e-01,\n",
       "       -2.9470e-01,  8.5009e-01,  1.0345e-01,  9.7010e-02,  1.1339e-01,\n",
       "        3.9502e-01,  5.9043e-02,  2.1978e-01,  1.8845e-01, -1.5891e-01,\n",
       "       -1.0301e-01,  3.3164e-01,  6.1477e-02, -2.9848e-01,  4.4510e-01,\n",
       "        4.7329e-01,  2.6312e-01, -1.8495e-01,  1.4652e-01, -3.1510e-02,\n",
       "        2.2908e-02, -2.5929e-01, -3.0862e-01,  1.7545e-03, -1.8962e-01,\n",
       "        5.4789e-01,  3.1194e-01,  2.4693e-01,  2.9929e-01, -7.4861e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0].vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "635870d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_token = nlp('bread')\n",
    "base_token[0].vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e1c73f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bread <-> bread 1.0\n",
      "sandwich <-> bread 0.6874560117721558\n",
      "burger <-> bread 0.544037401676178\n",
      "car <-> bread 0.16441147029399872\n",
      "tiger <-> bread 0.14492356777191162\n",
      "human <-> bread 0.21103660762310028\n",
      "wheat <-> bread 0.6572456359863281\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"bread sandwich burger car tiger human wheat\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text} <-> {base_token.text}\", token.similarity(base_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e8112cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_similarity(base_word,words_to_compare):\n",
    "    base_token = nlp(base_word)\n",
    "    doc = nlp(words_to_compare)\n",
    "    for token in doc:\n",
    "        print(f\"{token.text} <-> {base_token.text}\", token.similarity(base_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cabc2999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple <-> iphone 0.6339781284332275\n",
      "samsung <-> iphone 0.6678677797317505\n",
      "iphone <-> iphone 1.0\n",
      "dog <-> iphone 0.1743103712797165\n",
      "kitten <-> iphone 0.1468581259250641\n"
     ]
    }
   ],
   "source": [
    "print_similarity(\"iphone\",\"apple samsung iphone dog kitten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54c56012",
   "metadata": {},
   "outputs": [],
   "source": [
    "king = nlp.vocab[\"king\"].vector\n",
    "man = nlp.vocab[\"man\"].vector\n",
    "woman = nlp.vocab[\"woman\"].vector\n",
    "queen = nlp.vocab[\"queen\"].vector\n",
    "\n",
    "result = king - man + woman"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3558d7a8",
   "metadata": {},
   "source": [
    "Cosine similarity is a measure that quantifies how much two vectors point in the same direction, irrespective of their length. It's calculated by finding the cosine of the angle between the vectors, with values ranging from -1 to 1. A value of 1 indicates perfect similarity (vectors point in the same direction), 0 indicates no similarity (vectors are perpendicular), and -1 indicates perfect dissimilarity (vectors point in opposite directions). \n",
    "\n",
    "Cosine Similarity (A, B) = (A · B) / (||A|| * ||B||)\n",
    "\n",
    "Where: \n",
    "A · B is the dot product of vectors A and B.\n",
    "||A|| and ||B|| are the Euclidean norms (magnitudes) of vectors A and B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fb4d34a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78808445]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similarity([result],[queen])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
